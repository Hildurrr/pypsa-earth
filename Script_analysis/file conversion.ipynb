{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv to geojonson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON file has been saved to: C:\\Users\\hie\\pe_tan\\pypsa-earth\\data\\custom_lines.geojson\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import ast  # To safely evaluate the string representation of lists\n",
    "\n",
    "# File paths\n",
    "csv_path = r\"C:/Users/hie/pe_tan/pypsa-earth/data/custom_lines.csv\"  # Input CSV file\n",
    "geojson_path = r\"C:/Users/hie/pe_tan/pypsa-earth/data/custom_lines.geojson\"  # Output GeoJSON file\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_path, delimiter=\";\", encoding=\"utf-8\",dtype={\"line_id\": str})\n",
    "\n",
    "# Ensure the CSV contains the 'coordinates' column\n",
    "if \"coordinates\" not in df.columns:\n",
    "    raise ValueError(\"The CSV file must contain a 'coordinates' column.\")\n",
    "\n",
    "# Parse the 'coordinates' column and create LineString geometries\n",
    "def parse_coordinates(coordinates_str):\n",
    "    try:\n",
    "        # Safely evaluate the string representation of the list\n",
    "        coordinates = ast.literal_eval(coordinates_str)\n",
    "        return LineString(coordinates)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing 'coordinates': {coordinates_str} - {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply the parsing function to create the geometry column\n",
    "df[\"geometry\"] = df[\"coordinates\"].apply(parse_coordinates)\n",
    "\n",
    "# Drop the 'coordinates' column to match the structure of `all_clean_lines.geojson`\n",
    "df = df.drop(columns=[\"coordinates\"])\n",
    "\n",
    "# Convert to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")  # Assuming WGS84 (EPSG:4326)\n",
    "\n",
    "# Save to GeoJSON\n",
    "gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"GeoJSON file has been saved to: {geojson_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "geojonson to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been saved to: C:/Users/hie/pe_tan/pypsa-earth/data/custom_clean_lines.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import ast  # To safely evaluate the string representation of lists\n",
    "\n",
    "\n",
    "\n",
    "geojson_path=r\"C:/Users/hie/pe_tan/pypsa-earth/resources/veroni/osm/clean/all_clean_lines.geojson\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# File paths\n",
    "csv_path = \"C:/Users/hie/pe_tan/pypsa-earth/data/custom_clean_lines.csv\"  # outputCSV file\n",
    "\n",
    "\n",
    "# Load the GeoJSON file\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Extract coordinates from the geometry column and convert them to a string representation\n",
    "gdf[\"coordinates\"] = gdf[\"geometry\"].apply(lambda geom: list(geom.coords) if geom else None)\n",
    "\n",
    "# Drop the geometry column if not needed in the CSV\n",
    "df = gdf.drop(columns=[\"geometry\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"CSV file has been saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV to NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time column has been converted and saved to: C:\\Users\\hie\\pe_tan\\pypsa-earth\\data\\ssp2-2.6\\2040_base\\era5_2013\\Africa_converted.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "input_csv = r'C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2040_base/era5_2013/Africa.csv'\n",
    "output_csv = r'C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2040_base/era5_2013/Africa_converted.csv'\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(input_csv, sep=';', parse_dates=['time'], dayfirst=True)\n",
    "\n",
    "# Convert the 'time' column to the desired format (YYYY-MM-DD)\n",
    "df['time'] = df['time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(output_csv, sep=';', index=False)\n",
    "\n",
    "print(f\"Time column has been converted and saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetCDF file has been saved to: C:\\Users\\hie\\pe_tan\\pypsa-earth\\data\\ssp2-2.6\\2030_base\\era5_2013\\Africa.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "demand_profile_csv = r'C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2030_base/era5_2013/Africa_converted.csv'\n",
    "nc_file_path = r'C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2030_base/era5_2013/Africa.nc'\n",
    "\n",
    "\n",
    "# Convert the DataFrame to an xarray Dataset\n",
    "dataset = xr.Dataset.from_dataframe(df)\n",
    "\n",
    "# Save the Dataset to a NetCDF file\n",
    "dataset.to_netcdf(nc_file_path)\n",
    "\n",
    "print(f\"NetCDF file has been saved to: {nc_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region codes missing in dataset1: set()\n",
      "Region codes missing in dataset2: set()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "dataset1 = pd.read_csv(\"C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2030_base/era5_2013/Africa.csv\", sep=\";\")\n",
    "dataset2 = pd.read_csv(\"C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2030/era5_2018/Africa.csv\", sep=\";\")\n",
    "\n",
    "# Get unique region codes\n",
    "region_codes1 = set(dataset1[\"region_code\"].unique())\n",
    "region_codes2 = set(dataset2[\"region_code\"].unique())\n",
    "\n",
    "# Find mismatched region codes\n",
    "missing_in_dataset1 = region_codes2 - region_codes1\n",
    "missing_in_dataset2 = region_codes1 - region_codes2\n",
    "\n",
    "print(\"Region codes missing in dataset1:\", missing_in_dataset1)\n",
    "print(\"Region codes missing in dataset2:\", missing_in_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['region_code', 'time', 'region_name', 'Electricity demand'], dtype='object')\n",
      "Filtered data saved to: C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2040_base/era5_2013/filtered_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace 'your_file.csv' with your actual file path)\n",
    "# Assuming the dataset has columns: 'region_code', 'time_series', 'electricity_demand'\n",
    "file_path = 'C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2040_base/era5_2013/Africa.csv'\n",
    "data = pd.read_csv(file_path, sep=';')\n",
    "print(data.columns)\n",
    "# Filter the dataset to keep only rows where region_code is 'TZ'\n",
    "filtered_data = data[data['region_code'] == 'TZ']\n",
    "\n",
    "# Save the filtered dataset to a new CSV file (optional)\n",
    "output_file_path = 'C:/Users/hie/pe_tan/pypsa-earth/data/ssp2-2.6/2040_base/era5_2013/filtered_data.csv'\n",
    "filtered_data.to_csv(output_file_path, sep=';',index=False)\n",
    "\n",
    "print(\"Filtered data saved to:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypsa-earth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
